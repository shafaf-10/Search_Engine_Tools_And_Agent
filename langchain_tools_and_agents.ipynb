{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf3d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arxiv -- research\n",
    "## tools creation\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6bf0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf1c7574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use inbuilt tool of arxiv\n",
    "api_wrapper_arz = ArxivAPIWrapper(top_k_results=3,doc_content_chars_max=250)\n",
    "arz = ArxivQueryRun(api_wrapper=api_wrapper_arz)\n",
    "arz.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525a0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arz]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c39c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## custom tools [rag tools]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = (\n",
    "    OllamaEmbeddings(model=\"tinyllama\") ## by default it uses llama 2\n",
    "     \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7ecadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vector_db = FAISS.from_documents(documents,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e3fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e10d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith-search\",\n",
    "    \"Search any information about LangSmith\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a7d612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "768b24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arz,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f2bd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\abush\\\\OneDrive\\\\Documents\\\\Desktop\\\\Udemy\\\\Gen_AI\\\\Langchain\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langsmith-search', description='Search any information about LangSmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001B0D8E5AEF0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B0E9E41990>, search_kwargs={'k': 4}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001B0D8E5B010>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B0E9E41990>, search_kwargs={'k': 4}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5c7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run all this tools with agents and llm model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da2b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "816f9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tools with llm model\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\"\n",
    "\n",
    ",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f28dd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prompt template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9ea40c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B0FC2F9570>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B0FC2F9390>, model_name='openai/gpt-oss-120b', groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about LangSmith', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d75a22aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B0FC2F9570>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B0FC2F9390>, model_name='openai/gpt-oss-120b', groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about LangSmith', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\abush\\\\OneDrive\\\\Documents\\\\Desktop\\\\Udemy\\\\Gen_AI\\\\Langchain\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith-search', description='Search any information about LangSmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001B0D8E5AEF0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B0E9E41990>, search_kwargs={'k': 4}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001B0D8E5B010>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B0E9E41990>, search_kwargs={'k': 4}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executer \n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f3fdcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1706.03762'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on c\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Attention Is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer,\u001b[0m\u001b[32;1m\u001b[1;3m**Paper:** *Attention Is All You Need* (arXiv: 1706.03762)  \n",
      "**Authors:** Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin  \n",
      "**Year:** 2017 (submitted June 2017)\n",
      "\n",
      "---\n",
      "\n",
      "### Core Idea\n",
      "The paper proposes a **new neural network architecture called the *Transformer*** that dispenses with recurrence (RNNs/LSTMs) and convolution entirely, relying **solely on a mechanism called *self‑attention*** to model relationships between all positions in a sequence.\n",
      "\n",
      "### Key Components\n",
      "| Component | What it does |\n",
      "|-----------|--------------|\n",
      "| **Multi‑Head Self‑Attention** | Projects the input into several “heads” that each attend to different parts of the sequence, then concatenates the results. |\n",
      "| **Positional Encoding** | Adds deterministic sinusoidal vectors to the input embeddings so the model can infer token order despite lacking recurrence. |\n",
      "| **Feed‑Forward Networks** | Position‑wise fully‑connected layers applied after attention. |\n",
      "| **Layer Normalization & Residual Connections** | Stabilize training and allow deeper stacks. |\n",
      "| **Encoder‑Decoder Structure** | The encoder stacks self‑attention + feed‑forward layers; the decoder adds a second attention sub‑layer that attends to the encoder’s output. |\n",
      "\n",
      "### Why It Matters\n",
      "1. **Parallelism:** Because there are no sequential dependencies, training can be fully parallelized across sequence positions, dramatically speeding up computation compared with RNN‑based models.  \n",
      "2. **Long‑Range Dependencies:** Self‑attention directly connects every token to every other token, making it easier to capture distant relationships.  \n",
      "3. **State‑of‑the‑Art Performance:** On machine‑translation benchmarks (e.g., WMT 2014 English‑German and English‑French), the Transformer outperformed previous best models while using fewer parameters and less training time.  \n",
      "\n",
      "### Impact\n",
      "- **Foundation for Modern NLP:** The Transformer architecture underlies BERT, GPT, T5, RoBERTa, and virtually all large‑scale language models released after 2018.  \n",
      "- **Beyond NLP:** Variants have been applied to vision (ViT), speech, reinforcement learning, and even protein folding (AlphaFold).  \n",
      "- **Research Direction:** Sparked extensive work on efficient attention (e.g., Longformer, Performer) and on scaling models to billions of parameters.\n",
      "\n",
      "### Summary\n",
      "*Attention Is All You Need* introduced a **purely attention‑based sequence‑to‑sequence model** that replaces recurrence and convolution with multi‑head self‑attention, achieving faster training and superior performance on translation tasks. This architecture has become the backbone of today’s most powerful AI systems.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the paper 1706.03762 about?',\n",
       " 'output': '**Paper:**\\u202f*Attention Is All You Need* (arXiv:\\u202f1706.03762)  \\n**Authors:**\\u202fAshish\\u202fVaswani, Noam\\u202fShazeer, Niki\\u202fParmar, Jakob\\u202fUszkoreit, Llion\\u202fJones, Aidan\\u202fN.\\u202fGomez, Łukasz\\u202fKaiser, Illia\\u202fPolosukhin  \\n**Year:**\\u202f2017 (submitted June\\u202f2017)\\n\\n---\\n\\n### Core Idea\\nThe paper proposes a **new neural network architecture called the *Transformer*** that dispenses with recurrence (RNNs/LSTMs) and convolution entirely, relying **solely on a mechanism called *self‑attention*** to model relationships between all positions in a sequence.\\n\\n### Key Components\\n| Component | What it does |\\n|-----------|--------------|\\n| **Multi‑Head Self‑Attention** | Projects the input into several “heads” that each attend to different parts of the sequence, then concatenates the results. |\\n| **Positional Encoding** | Adds deterministic sinusoidal vectors to the input embeddings so the model can infer token order despite lacking recurrence. |\\n| **Feed‑Forward Networks** | Position‑wise fully‑connected layers applied after attention. |\\n| **Layer Normalization & Residual Connections** | Stabilize training and allow deeper stacks. |\\n| **Encoder‑Decoder Structure** | The encoder stacks self‑attention + feed‑forward layers; the decoder adds a second attention sub‑layer that attends to the encoder’s output. |\\n\\n### Why It Matters\\n1. **Parallelism:** Because there are no sequential dependencies, training can be fully parallelized across sequence positions, dramatically speeding up computation compared with RNN‑based models.  \\n2. **Long‑Range Dependencies:** Self‑attention directly connects every token to every other token, making it easier to capture distant relationships.  \\n3. **State‑of‑the‑Art Performance:** On machine‑translation benchmarks (e.g., WMT\\u202f2014 English‑German and English‑French), the Transformer outperformed previous best models while using fewer parameters and less training time.  \\n\\n### Impact\\n- **Foundation for Modern NLP:** The Transformer architecture underlies BERT, GPT, T5, RoBERTa, and virtually all large‑scale language models released after 2018.  \\n- **Beyond NLP:** Variants have been applied to vision (ViT), speech, reinforcement learning, and even protein folding (AlphaFold).  \\n- **Research Direction:** Sparked extensive work on efficient attention (e.g., Longformer, Performer) and on scaling models to billions of parameters.\\n\\n### Summary\\n*Attention Is All You Need* introduced a **purely attention‑based sequence‑to‑sequence model** that replaces recurrence and convolution with multi‑head self‑attention, achieving faster training and superior performance on translation tasks. This architecture has become the backbone of today’s most powerful AI systems.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"what is the paper 1706.03762 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf0857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
